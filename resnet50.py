# -*- coding: utf-8 -*-
"""ResNet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FPMRkd7Gt5IsP-zI3dN1XOzOFDXHb9EY
"""

import tensorflow as tf
!pip install --quiet kagglehub
!pip install --quiet opencv-python
import kagglehub
import os
import random
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import cv2
import shutil
from collections import defaultdict
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
from sklearn.utils.class_weight import compute_class_weight
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras import mixed_precision
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.metrics import Precision, Recall
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, Callback

device_name = tf.test.gpu_device_name()
print("GPU device:", device_name if device_name else "GPU not found")

dataset_path = kagglehub.dataset_download("ninadaithal/imagesoasis")
print("Dataset is fully downloaded to:", dataset_path)

SEED = 42
random.seed(SEED)
np.random.seed(SEED)
tf.random.set_seed(SEED)

for root, dirs, files in os.walk(dataset_path):
    level = root.replace(dataset_path, '').count(os.sep)
    indent = ' ' * 2 * level
    print(f"{indent}{os.path.basename(root)}/")
    subindent = ' ' * 2 * (level + 1)
    for f in files[:3]:
        print(f"{subindent}{f}")

original_data_path = os.path.join(dataset_path, "Data")

print("Total images per class\n")

for cls in os.listdir(original_data_path):
    class_path = os.path.join(original_data_path, cls)
    if os.path.isdir(class_path):
        num_images = len(os.listdir(class_path))
        print(f"{cls}: {num_images} images")

original_path = os.path.join(dataset_path, "Data")
classes = ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']
splits = ['train', 'val', 'test']

base_dir = "/content/sota_split"

if os.path.exists(base_dir):
    shutil.rmtree(base_dir)

for split in splits:
    for cls in classes:
        os.makedirs(os.path.join(base_dir, split, cls))

for cls in classes:
    src_dir = os.path.join(original_path, cls)
    images = os.listdir(src_dir)
    train_imgs, temp_imgs = train_test_split(images, test_size=0.3, random_state=SEED)
    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=SEED)

    for img in train_imgs:
        shutil.copy(os.path.join(src_dir, img), os.path.join(base_dir, 'train', cls, img))
    for img in val_imgs:
        shutil.copy(os.path.join(src_dir, img), os.path.join(base_dir, 'val', cls, img))
    for img in test_imgs:
        shutil.copy(os.path.join(src_dir, img), os.path.join(base_dir, 'test', cls, img))

print("The dataset is split into train/val/test and organized into seperate maps")

counts = defaultdict(lambda: defaultdict(int))

for split in splits:
    for cls in classes:
        dir_path = os.path.join(base_dir, split, cls)
        if os.path.isdir(dir_path):
            num_images = len([f for f in os.listdir(dir_path) if f.lower().endswith(('.jpg'))])
            counts[cls][split] = num_images

print("\nTotal images per class after splitting:\n")
for cls in classes:
    print(f"{cls:<20} | Train: {counts[cls]['train']:>5} | Val: {counts[cls]['val']:>5} | Test: {counts[cls]['test']:>5}")

def add_salt_pepper_noise(image, amount=0.02):
    if len(image.shape) == 2:
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

    output = np.copy(image)
    h, w, c = image.shape
    num_pixels = int(amount * h * w)

    for _ in range(num_pixels // 2):
        x = np.random.randint(0, w)
        y = np.random.randint(0, h)
        output[y, x] = [255] * c

    for _ in range(num_pixels // 2):
        x = np.random.randint(0, w)
        y = np.random.randint(0, h)
        output[y, x] = [0] * c

    return output


def augment_salt_pepper_for_class(class_name, base_dir, num_augmented=0, overwrite_noise=False, fraction_of_images=1.0):
    class_dir = os.path.join(base_dir, "train", class_name)
    images = os.listdir(class_dir)

    print(f"Salt and Pepper for {class_name} | augment={num_augmented} | overwrite={overwrite_noise} | fraction of images={fraction_of_images}")

    selected_images = random.sample(images, int(len(images) * fraction_of_images))

    for img_name in selected_images:
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

        if img is None:
            print(f"Can't read the image {img_path}, jumping to next one.")
            continue

        if overwrite_noise:
            noisy = add_salt_pepper_noise(img, amount=0.02)
            cv2.imwrite(img_path, noisy)

        for i in range(num_augmented):
            noisy = add_salt_pepper_noise(img, amount=0.02)
            out_name = img_name.replace(".jpg", f"_sp{i}.jpg")
            out_path = os.path.join(class_dir, out_name)
            cv2.imwrite(out_path, noisy)

base_dir = "/content/sota_split"

augment_salt_pepper_for_class("Moderate Dementia", base_dir, num_augmented=5, overwrite_noise=False, fraction_of_images=1)
augment_salt_pepper_for_class("Mild Dementia", base_dir, num_augmented=5, overwrite_noise=False, fraction_of_images=1)
augment_salt_pepper_for_class("Very mild Dementia", base_dir, num_augmented=2, overwrite_noise=False, fraction_of_images=1)
augment_salt_pepper_for_class("Non Demented", base_dir, num_augmented=0, overwrite_noise=True, fraction_of_images=0.25)

def count_images_after_split(base_dir):
    count_per_split = defaultdict(lambda: defaultdict(int))
    total_per_class = defaultdict(int)

    for split in ['train', 'val', 'test']:
        split_path = os.path.join(base_dir, split)
        for cls in os.listdir(split_path):
            class_path = os.path.join(split_path, cls)
            if os.path.isdir(class_path):
                num_images = len(os.listdir(class_path))
                count_per_split[split][cls] = num_images
                total_per_class[cls] += num_images

    print("Images in each subclass per split:\n")
    for split in count_per_split:
        print(f"{split.upper()}:")
        for cls in count_per_split[split]:
            print(f"{cls}: {count_per_split[split][cls]} images")
        print()

    print("Total per subclass:")
    for cls, total in total_per_class.items():
        print(f"{cls}: {total} images")

count_images_after_split(base_dir)

IMG_SIZE = (160, 160)
BATCH_SIZE = 64

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=10,
    width_shift_range=0.05,
    height_shift_range=0.05,
    zoom_range=0.05,
    brightness_range=(0.9, 1.1),
    horizontal_flip=False,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    os.path.join(base_dir, 'train'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True,
    seed=SEED
)

val_generator = val_test_datagen.flow_from_directory(
    os.path.join(base_dir, 'val'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

test_generator = val_test_datagen.flow_from_directory(
    os.path.join(base_dir, 'test'),
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

labels = train_generator.classes
class_weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(labels),
    y=labels
)

class_weights_dict = dict(enumerate(class_weights))

class_indices = train_generator.class_indices
index_to_class = {v: k for k, v in class_indices.items()}
print("\nIndex to classname:\n")
for index, class_name in index_to_class.items():
    print(f"{index}, {class_name}")

class_weights_named = {
    index_to_class[i]: float(w) for i, w in enumerate(class_weights)
}

print("\nClass weights per class:\n")
for class_name, weight in class_weights_named.items():
    print(f"{class_name}, {weight:.4f}")

device_name = tf.test.gpu_device_name()
print("GPU device:", device_name if device_name else "GPU not found")

mixed_precision.set_global_policy('mixed_float16')

base_model = ResNet50(
    weights='imagenet',
    include_top=False,
    input_shape=(160, 160, 3)
)

for layer in base_model.layers[:-10]:
    layer.trainable = False
for layer in base_model.layers[-10:]:
    layer.trainable = True

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
predictions = Dense(
    train_generator.num_classes,
    activation='softmax',
    dtype='float32'
)(x)

resnet_model = Model(
    inputs=base_model.input,
    outputs=predictions,
    name="ResNet50sota"
)

resnet_model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss='categorical_crossentropy',
    metrics=[
        'accuracy',
        Precision(name='precision'),
        Recall(name='recall')
    ]
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=7,
    restore_best_weights=True,
    verbose=1
)

lr_scheduler = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=4,
    verbose=1,
    min_lr=0.000001
)

resnet_model.summary()

EPOCHS = 20

history_resnet = resnet_model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS,
    class_weight=class_weights_dict,
    callbacks=[early_stop, lr_scheduler]

)

results = resnet_model.evaluate(test_generator)
test_loss = results[0]
test_acc = results[1]
test_precision = results[2]
test_recall = results[3]

print(f"\nTest Accuracy:  {test_acc:.4f}")
print(f"Test Precision: {test_precision:.4f}")
print(f"Test Recall:    {test_recall:.4f}")
print(f"Test Loss:      {test_loss:.4f}")

def plot_training_curves(history):
    acc = history_resnet.history['accuracy']
    val_acc = history_resnet.history['val_accuracy']
    loss = history_resnet.history['loss']
    val_loss = history_resnet.history['val_loss']
    epochs = range(1, len(acc) + 1)

    plt.figure(figsize=(14, 5))

    plt.subplot(1, 2, 1)
    plt.plot(epochs, acc, 'b', label='Training accuracy')
    plt.plot(epochs, val_acc, 'g', label='Validation accuracy')
    plt.title('Training and Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(epochs, loss, 'b', label='Training loss')
    plt.plot(epochs, val_loss, 'g', label='Validation loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

plot_training_curves(history_resnet)

y_pred = resnet_model.predict(test_generator)
y_pred = np.argmax(y_pred, axis=1)
y_true = test_generator.classes

cm = confusion_matrix(y_true, y_pred, normalize='true')
class_labels = list(train_generator.class_indices.keys())

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)
disp.plot(cmap=plt.cm.Blues, values_format=".2")
plt.title("Confusion Matrix - ResNet50-sota")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("Classification Report")
print(classification_report(y_true, y_pred, target_names=class_labels)